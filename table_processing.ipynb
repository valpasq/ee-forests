{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook for merging Earth Engine exports with FIA results.\n",
        "This notebook takes remote sensing dataset summaries exported from Earth Engine and FIA Forest and Timberlands summaries and merges into a single table for downstream analysis.\n"
      ],
      "metadata": {
        "id": "tG9FMAPlatK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VCGEv3A3lIP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mxp56pPVq_K",
        "outputId": "bcd23e4a-7ef5-4f0b-a565-fb4e0e5268ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VERSION = 'v5-0'\n",
        "\n",
        "# Tabular results.\n",
        "DRIVE_DIR = '/content/drive/MyDrive/LandSystem_RemoteSensing/Forest-Product-Comparison/datasets/'\n",
        "FIA_FOREST_DIR = DRIVE_DIR + 'fia_forest_area/'\n",
        "FIA_TIMBERLANDS_DIR = DRIVE_DIR + 'fia_timberland_area/'\n",
        "EE_DIR = DRIVE_DIR + VERSION + '/'\n",
        "\n",
        "# Output locations.\n",
        "OUTPUT_DIR = DRIVE_DIR + VERSION + '_merged/'\n"
      ],
      "metadata": {
        "id": "DMRN3kDH3vi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "us_state_to_abbrev = {\n",
        "    \"Alabama\": \"AL\",\n",
        "    \"Alaska\": \"AK\",\n",
        "    \"Arizona\": \"AZ\",\n",
        "    \"Arkansas\": \"AR\",\n",
        "    \"California\": \"CA\",\n",
        "    \"Colorado\": \"CO\",\n",
        "    \"Connecticut\": \"CT\",\n",
        "    \"Delaware\": \"DE\",\n",
        "    \"Florida\": \"FL\",\n",
        "    \"Georgia\": \"GA\",\n",
        "    \"Hawaii\": \"HI\",\n",
        "    \"Idaho\": \"ID\",\n",
        "    \"Illinois\": \"IL\",\n",
        "    \"Indiana\": \"IN\",\n",
        "    \"Iowa\": \"IA\",\n",
        "    \"Kansas\": \"KS\",\n",
        "    \"Kentucky\": \"KY\",\n",
        "    \"Louisiana\": \"LA\",\n",
        "    \"Maine\": \"ME\",\n",
        "    \"Maryland\": \"MD\",\n",
        "    \"Massachusetts\": \"MA\",\n",
        "    \"Michigan\": \"MI\",\n",
        "    \"Minnesota\": \"MN\",\n",
        "    \"Mississippi\": \"MS\",\n",
        "    \"Missouri\": \"MO\",\n",
        "    \"Montana\": \"MT\",\n",
        "    \"Nebraska\": \"NE\",\n",
        "    \"Nevada\": \"NV\",\n",
        "    \"New Hampshire\": \"NH\",\n",
        "    \"New Jersey\": \"NJ\",\n",
        "    \"New Mexico\": \"NM\",\n",
        "    \"New York\": \"NY\",\n",
        "    \"North Carolina\": \"NC\",\n",
        "    \"North Dakota\": \"ND\",\n",
        "    \"Ohio\": \"OH\",\n",
        "    \"Oklahoma\": \"OK\",\n",
        "    \"Oregon\": \"OR\",\n",
        "    \"Pennsylvania\": \"PA\",\n",
        "    \"Rhode Island\": \"RI\",\n",
        "    \"South Carolina\": \"SC\",\n",
        "    \"South Dakota\": \"SD\",\n",
        "    \"Tennessee\": \"TN\",\n",
        "    \"Texas\": \"TX\",\n",
        "    \"Utah\": \"UT\",\n",
        "    \"Vermont\": \"VT\",\n",
        "    \"Virginia\": \"VA\",\n",
        "    \"Washington\": \"WA\",\n",
        "    \"West Virginia\": \"WV\",\n",
        "    \"Wisconsin\": \"WI\",\n",
        "    \"Wyoming\": \"WY\",\n",
        "    \"District of Columbia\": \"DC\",\n",
        "    \"American Samoa\": \"AS\",\n",
        "    \"Guam\": \"GU\",\n",
        "    \"Northern Mariana Islands\": \"MP\",\n",
        "    \"Puerto Rico\": \"PR\",\n",
        "    \"United States Minor Outlying Islands\": \"UM\",\n",
        "    \"U.S. Virgin Islands\": \"VI\",\n",
        "}"
      ],
      "metadata": {
        "id": "4f6Dayixhz9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge TX-1 and TX-1 and write new TX csv.\n",
        "tx_1 = pd.read_csv(EE_DIR + 'fpc_' + VERSION + '_TX-1.csv')\n",
        "tx_2 = pd.read_csv(EE_DIR + 'fpc_' + VERSION + '_TX-2.csv')\n",
        "\n",
        "tx = tx_1.add(tx_2)\n",
        "\n",
        "tx.drop(columns=['dataset_id', 'state'], inplace=True)\n",
        "tx.insert(0, 'dataset_id', tx_1['dataset_id'])\n",
        "tx.insert(1, 'state', 'TX')\n",
        "tx.set_index('dataset_id', inplace=True)\n",
        "\n",
        "tx.to_csv(EE_DIR + 'fpc_' + VERSION + '_TX.csv')"
      ],
      "metadata": {
        "id": "C0CeiVoA9MNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Get file lists.\n",
        "fia_forest_files = list(os.listdir(FIA_FOREST_DIR))\n",
        "fia_timberlands_files = list(os.listdir(FIA_TIMBERLANDS_DIR))\n",
        "ee_files = list(os.listdir(EE_DIR))\n",
        "\n",
        "# Check lists for name formatting.\n",
        "print(fia_forest_files)\n",
        "print(fia_timberlands_files)\n",
        "print(ee_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B48u8BbF4Otp",
        "outputId": "952b0421-cbf0-433e-e68e-1d53203caae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['VAR_forest_area_NV.csv', 'VAR_forest_area_ME.csv', 'VAR_forest_area_IL.csv', 'VAR_forest_area_CT.csv', 'VAR_forest_area_MO.csv', 'VAR_forest_area_NH.csv', 'VAR_forest_area_MS.csv', 'VAR_forest_area_MA.csv', 'VAR_forest_area_ND.csv', 'VAR_forest_area_OH.csv', 'VAR_forest_area_PA.csv', 'VAR_forest_area_LA.csv', 'VAR_forest_area_NE.csv', 'VAR_forest_area_TX.csv', 'VAR_forest_area_GA.csv', 'VAR_forest_area_OR.csv', 'VAR_forest_area_FL.csv', 'VAR_forest_area_IN.csv', 'VAR_forest_area_KS.csv', 'VAR_forest_area_SC.csv', 'VAR_forest_area_DE.csv', 'VAR_forest_area_NC.csv', 'VAR_forest_area_NY.csv', 'VAR_forest_area_TN.csv', 'VAR_forest_area_AR.csv', 'VAR_forest_area_RI.csv', 'VAR_forest_area_NM.csv', 'VAR_forest_area_MT.csv', 'VAR_forest_area_OK.csv', 'VAR_forest_area_KY.csv', 'VAR_forest_area_MI.csv', 'VAR_forest_area_CO.csv', 'VAR_forest_area_CA.csv', 'VAR_forest_area_MN.csv', 'VAR_forest_area_NJ.csv', 'VAR_forest_area_UT.csv', 'VAR_forest_area_SD.csv', 'VAR_forest_area_IA.csv', 'VAR_forest_area_AL.csv', 'VAR_forest_area_ID.csv', 'VAR_forest_area_MD.csv', 'VAR_forest_area_AZ.csv', 'VAR_forest_area_VT.csv', 'VAR_forest_area_WI.csv', 'VAR_forest_area_WA.csv', 'VAR_forest_area_WY.csv', 'VAR_forest_area_VA.csv', 'VAR_forest_area_WV.csv']\n",
            "['VAR_timberland_area_CO.csv', 'VAR_timberland_area_AL.csv', 'VAR_timberland_area_IA.csv', 'VAR_timberland_area_NM.csv', 'VAR_timberland_area_KY.csv', 'VAR_timberland_area_DE.csv', 'VAR_timberland_area_NH.csv', 'VAR_timberland_area_LA.csv', 'VAR_timberland_area_MI.csv', 'VAR_timberland_area_CT.csv', 'VAR_timberland_area_NY.csv', 'VAR_timberland_area_ND.csv', 'VAR_timberland_area_ID.csv', 'VAR_timberland_area_TX.csv', 'VAR_timberland_area_AZ.csv', 'VAR_timberland_area_IL.csv', 'VAR_timberland_area_RI.csv', 'VAR_timberland_area_NJ.csv', 'VAR_timberland_area_MA.csv', 'VAR_timberland_area_UT.csv', 'VAR_timberland_area_GA.csv', 'VAR_timberland_area_ME.csv', 'VAR_timberland_area_NE.csv', 'VAR_timberland_area_PA.csv', 'VAR_timberland_area_FL.csv', 'VAR_timberland_area_CA.csv', 'VAR_timberland_area_NC.csv', 'VAR_timberland_area_MT.csv', 'VAR_timberland_area_OH.csv', 'VAR_timberland_area_TN.csv', 'VAR_timberland_area_MS.csv', 'VAR_timberland_area_SC.csv', 'VAR_timberland_area_IN.csv', 'VAR_timberland_area_MO.csv', 'VAR_timberland_area_MD.csv', 'VAR_timberland_area_OK.csv', 'VAR_timberland_area_SD.csv', 'VAR_timberland_area_AR.csv', 'VAR_timberland_area_NV.csv', 'VAR_timberland_area_OR.csv', 'VAR_timberland_area_KS.csv', 'VAR_timberland_area_MN.csv', 'VAR_timberland_area_WY.csv', 'VAR_timberland_area_VA.csv', 'VAR_timberland_area_WV.csv', 'VAR_timberland_area_WA.csv', 'VAR_timberland_area_WI.csv', 'VAR_timberland_area_VT.csv']\n",
            "['fpc_v5-0_DE.csv', 'fpc_v5-0_RI.csv', 'fpc_v5-0_NJ.csv', 'fpc_v5-0_CT.csv', 'fpc_v5-0_NH.csv', 'fpc_v5-0_MA.csv', 'fpc_v5-0_VT.csv', 'fpc_v5-0_IN.csv', 'fpc_v5-0_MD.csv', 'fpc_v5-0_AR.csv', 'fpc_v5-0_SC.csv', 'fpc_v5-0_IA.csv', 'fpc_v5-0_LA.csv', 'fpc_v5-0_IL.csv', 'fpc_v5-0_WV.csv', 'fpc_v5-0_NY.csv', 'fpc_v5-0_AL.csv', 'fpc_v5-0_WI.csv', 'fpc_v5-0_NE.csv', 'fpc_v5-0_SD.csv', 'fpc_v5-0_ND.csv', 'fpc_v5-0_KY.csv', 'fpc_v5-0_TN.csv', 'fpc_v5-0_WY.csv', 'fpc_v5-0_WA.csv', 'fpc_v5-0_PA.csv', 'fpc_v5-0_MI.csv', 'fpc_v5-0_MO.csv', 'fpc_v5-0_ME.csv', 'fpc_v5-0_OR.csv', 'fpc_v5-0_OH.csv', 'fpc_v5-0_NC.csv', 'fpc_v5-0_MS.csv', 'fpc_v5-0_OK.csv', 'fpc_v5-0_KS.csv', 'fpc_v5-0_NM.csv', 'fpc_v5-0_FL.csv', 'fpc_v5-0_MN.csv', 'fpc_v5-0_GA.csv', 'fpc_v5-0_NV.csv', 'fpc_v5-0_ID.csv', 'fpc_v5-0_TX-1.csv', 'fpc_v5-0_VA.csv', 'fpc_v5-0_CO.csv', 'fpc_v5-0_UT.csv', 'fpc_v5-0_AZ.csv', 'fpc_v5-0_MT.csv', 'fpc_v5-0_TX-2.csv', 'fpc_v5-0_CA.csv', 'fpc_v5-0_TX.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_fia_results(\n",
        "    dir: str,\n",
        "    basename: str,\n",
        "    product_id: str,\n",
        "    state: str) -> pd.DataFrame:\n",
        "\n",
        "  # Read in FIA results.\n",
        "  fia_csv = pd.read_csv(f'{dir}{basename}_{state}.csv', index_col='YEAR')\n",
        "\n",
        "  # Calculate FIA upper and lower bounds.\n",
        "  fia_csv[product_id + '_upper'] = fia_csv['Area_Km2'] + fia_csv['StandDev_Km2']\n",
        "  fia_csv[product_id + '_lower'] = fia_csv['Area_Km2'] - fia_csv['StandDev_Km2']\n",
        "\n",
        "  # Clean up FIA table.\n",
        "  fia_csv.rename(columns={'Area_Km2': product_id},\n",
        "                 inplace=True)\n",
        "  fia_csv.drop(columns=[\n",
        "                        'Unnamed: 0',\n",
        "                        'StandDev_Km2',\n",
        "                        'Total_Variance',\n",
        "                        'N_Forested'],\n",
        "               inplace=True)\n",
        "\n",
        "  # Transpose and set attributes.\n",
        "  fia_csv_rows = fia_csv.transpose().reset_index()\n",
        "  fia_csv_rows.rename(columns={'index': 'dataset_id'}, inplace=True)\n",
        "  fia_csv_rows['state'] = state\n",
        "\n",
        "  # Convert FIA column headers to strings to match EE results.\n",
        "  fia_csv_rows.columns = fia_csv_rows.columns.astype(str)\n",
        "\n",
        "  return fia_csv_rows"
      ],
      "metadata": {
        "id": "CQANfG9JRQU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GHG_FIA_CSV = DRIVE_DIR + 'USFS_RDS-2021-0035/Data/CSV/LULUC_area.csv'\n",
        "\n",
        "# Convert from thousands of hectares to km2\n",
        "K_HA_TO_KM2 = 1000 * 0.01\n",
        "\n",
        "\n",
        "def process_ghg_results(state: str, product_id: str) -> pd.DataFrame:\n",
        "  ghg_fia = pd.read_csv(GHG_FIA_CSV)\n",
        "\n",
        "  # Column with forest estimates.\n",
        "  LULUC_COL = 'Land Use & Land Use Change Categories'\n",
        "\n",
        "  ghg_fia['state'] = ghg_fia['State'].replace(us_state_to_abbrev)\n",
        "  ghg_fia['dataset_id'] = product_id\n",
        "  ghg_fia_forest = ghg_fia.loc[ghg_fia[LULUC_COL] == 'Total Forest Land'].copy()\n",
        "  ghg_fia_forest.drop(columns=['State', LULUC_COL], inplace=True)\n",
        "\n",
        "  ghg_fia_forest_select = ghg_fia_forest.loc[ghg_fia['state'] == state].copy()\n",
        "  ghg_fia_forest_select.iloc[:, :-2] = ghg_fia_forest_select.iloc[:, :-2] * K_HA_TO_KM2\n",
        "\n",
        "  return ghg_fia_forest_select\n"
      ],
      "metadata": {
        "id": "u-v_HjJa5GI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NRI_NONFEDERAL_CSV = DRIVE_DIR + 'nri_nonfederal_forest/nri_grazed_notgrazed_total_forest_acres.csv'\n",
        "\n",
        "# Convert acres to km2\n",
        "ACRE_TO_KM2 = (1 / 247.1)\n",
        "\n",
        "\n",
        "def process_nri_results(state: str, product_id: str, col_value: str) -> pd.DataFrame:\n",
        "  nri_nonfederal = pd.read_csv(NRI_NONFEDERAL_CSV)\n",
        "\n",
        "  # Column with forest estimates.\n",
        "  LULUC_COL = 'forest_type'\n",
        "\n",
        "  nri_nonfederal['dataset_id'] = product_id\n",
        "  nri_nonfederal = nri_nonfederal.loc[nri_nonfederal[LULUC_COL] == col_value].copy()\n",
        "  nri_nonfederal.drop(columns=['forest_type', '1982'], inplace=True)\n",
        "\n",
        "  nri_nonfederal_select = nri_nonfederal.loc[nri_nonfederal['state'] == state].copy()\n",
        "  nri_nonfederal_select.iloc[:, 1:-1] = nri_nonfederal_select.iloc[:, 1:-1] * ACRE_TO_KM2\n",
        "\n",
        "  return nri_nonfederal_select"
      ],
      "metadata": {
        "id": "65K82146KuJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_table(ee_file: str) -> pd.DataFrame:\n",
        "  # Get state code from filename.\n",
        "  state = ee_file.split('_')[2].split('.')[0]\n",
        "\n",
        "  # Read in EE results.\n",
        "  ee_csv = pd.read_csv(EE_DIR + ee_file)\n",
        "\n",
        "  # Convert EE results from m2 to km2\n",
        "  ee_csv.iloc[:, 2::] = ee_csv.iloc[:, 2::] / (1000 * 1000)\n",
        "\n",
        "  forest = process_fia_results(\n",
        "      FIA_FOREST_DIR, 'VAR_forest_area', 'FIA_forest', state)\n",
        "  timberlands = process_fia_results(\n",
        "      FIA_TIMBERLANDS_DIR, 'VAR_timberland_area', 'FIA_timberland', state)\n",
        "\n",
        "  ghg_forests = process_ghg_results(state, 'EPA_forested')\n",
        "\n",
        "  nri_total = process_nri_results(state, 'NRI_total', 'total')\n",
        "  nri_grazed = process_nri_results(state, 'NRI_grazed', 'grazed')\n",
        "  nri_notgrazed = process_nri_results(state, 'NRI_notgrazed', 'notgrazed')\n",
        "\n",
        "  # Append FIA rows to EE table.\n",
        "  final_csv = pd.concat(\n",
        "      [ee_csv, forest, timberlands, ghg_forests, nri_total, nri_grazed, nri_notgrazed]).reset_index().drop(columns=['index'])\n",
        "  final_csv.set_index('dataset_id', inplace=True)\n",
        "\n",
        "  # Export final merged table to csv.\n",
        "  name = VERSION + f'_merged_{state}'\n",
        "  final_csv.to_csv(OUTPUT_DIR + name + '.csv')\n",
        "\n",
        "  return final_csv.sort_index()"
      ],
      "metadata": {
        "id": "vQFLNrQ--eLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conus_df = pd.DataFrame()\n",
        "\n",
        "# Loop over EE results.\n",
        "for ee_file in ee_files:\n",
        "  state = ee_file.split('_')[2].split('.')[0]\n",
        "\n",
        "  # Check if we have a matching FIA file.\n",
        "  if any(\n",
        "      (state in f) for f in fia_forest_files) and any(\n",
        "          (state in f) for f in fia_timberlands_files):\n",
        "    print(f'Processing {state}')\n",
        "\n",
        "    # Process and merge results files.\n",
        "    table = process_table(ee_file)\n",
        "\n",
        "    conus_df = pd.concat([conus_df, table]).groupby(level=0).sum(numeric_only=True)\n",
        "    conus_df.replace(0, np.nan, inplace=True)\n",
        "\n",
        "  else:\n",
        "    print(f'No FIA results for this state: {state}')\n",
        "\n",
        "print('Done!')\n",
        "\n",
        "conus_df.to_csv(OUTPUT_DIR + 'v5-0_merged_CONUS.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydDucbKN5qgr",
        "outputId": "ddf8f1b0-5e99-4704-bfcf-4ccab46871f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing DE\n",
            "Processing RI\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-7f0f853a0a34>:18: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  nri_nonfederal_select.iloc[:, 1:-1] = nri_nonfederal_select.iloc[:, 1:-1] * ACRE_TO_KM2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing NJ\n",
            "Processing CT\n",
            "Processing NH\n",
            "Processing MA\n",
            "Processing VT\n",
            "Processing IN\n",
            "Processing MD\n",
            "Processing AR\n",
            "Processing SC\n",
            "Processing IA\n",
            "Processing LA\n",
            "Processing IL\n",
            "Processing WV\n",
            "Processing NY\n",
            "Processing AL\n",
            "Processing WI\n",
            "Processing NE\n",
            "Processing SD\n",
            "Processing ND\n",
            "Processing KY\n",
            "Processing TN\n",
            "Processing WY\n",
            "Processing WA\n",
            "Processing PA\n",
            "Processing MI\n",
            "Processing MO\n",
            "Processing ME\n",
            "Processing OR\n",
            "Processing OH\n",
            "Processing NC\n",
            "Processing MS\n",
            "Processing OK\n",
            "Processing KS\n",
            "Processing NM\n",
            "Processing FL\n",
            "Processing MN\n",
            "Processing GA\n",
            "Processing NV\n",
            "Processing ID\n",
            "No FIA results for this state: TX-1\n",
            "Processing VA\n",
            "Processing CO\n",
            "Processing UT\n",
            "Processing AZ\n",
            "Processing MT\n",
            "No FIA results for this state: TX-2\n",
            "Processing CA\n",
            "Processing TX\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}